{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c590b785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d0dca8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 / unknown"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AirlineTweets.csv'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download data from provided\n",
    "https://www.dropbox.com/s/lkd0eklmi64m9xm/AirlineTweets.csv?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "759aa33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6866e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AirlineTweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eafb2431",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['airline_sentiment','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfee8912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['airline_sentiment'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b40cf86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = { 'positive': 1, 'negative': 0, 'neutral': 2}\n",
    "df['target'] = df['airline_sentiment'].map(target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1abd875d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[['text','target']]\n",
    "df1.columns = ['sentence','label']\n",
    "df1.to_csv('data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ef985e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = df1.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f4c19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78e911f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (file://C:/Users/Yuvaraj S/.cache/huggingface/datasets/csv/default-c267b38c8f8a39ac/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Loading a dataset cached in a LocalFileSystem is not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m raw_dataset \u001b[38;5;241m=\u001b[39m load_dataset(path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m,data_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Yashwanth\\Jupyter\\Lib\\site-packages\\datasets\\load.py:1810\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[0;32m   1806\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[0;32m   1807\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1808\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[0;32m   1809\u001b[0m )\n\u001b[1;32m-> 1810\u001b[0m ds \u001b[38;5;241m=\u001b[39m builder_instance\u001b[38;5;241m.\u001b[39mas_dataset(split\u001b[38;5;241m=\u001b[39msplit, verification_mode\u001b[38;5;241m=\u001b[39mverification_mode, in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory)\n\u001b[0;32m   1811\u001b[0m \u001b[38;5;66;03m# Rename and cast features to match task schema\u001b[39;00m\n\u001b[0;32m   1812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Yashwanth\\Jupyter\\Lib\\site-packages\\datasets\\builder.py:1107\u001b[0m, in \u001b[0;36mDatasetBuilder.as_dataset\u001b[1;34m(self, split, run_post_process, verification_mode, ignore_verifications, in_memory)\u001b[0m\n\u001b[0;32m   1105\u001b[0m is_local \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_remote_filesystem(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading a dataset cached in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fs)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir):\n\u001b[0;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1110\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: could not find data in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please make sure to call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuilder.download_and_prepare(), or use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1112\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets.load_dataset() before trying to access the Dataset object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1113\u001b[0m     )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Loading a dataset cached in a LocalFileSystem is not supported."
     ]
    }
   ],
   "source": [
    "raw_dataset = load_dataset(path='csv',data_files = 'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0ee56c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "elements = literal_eval(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f4947f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = Dataset.from_pandas(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2935b25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = raw_data.train_test_split(test_size=0.3, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27d70d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 10248\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label'],\n",
       "        num_rows: 4392\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a02154b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import AutoTokenizer and create tokenizer object\n",
    "from transformers import AutoTokenizer\n",
    "checkpoint = 'bert-base-cased'\n",
    "tokernizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff9d9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    return tokernizer(batch['sentence'], truncation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c775a17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = split.map(tokenize_fn, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8b1f151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "efc8c0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a68c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b9ab1d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "BertForSequenceClassification                                --\n",
       "├─BertModel: 1-1                                             --\n",
       "│    └─BertEmbeddings: 2-1                                   --\n",
       "│    │    └─Embedding: 3-1                                   22,268,928\n",
       "│    │    └─Embedding: 3-2                                   393,216\n",
       "│    │    └─Embedding: 3-3                                   1,536\n",
       "│    │    └─LayerNorm: 3-4                                   1,536\n",
       "│    │    └─Dropout: 3-5                                     --\n",
       "│    └─BertEncoder: 2-2                                      --\n",
       "│    │    └─ModuleList: 3-6                                  85,054,464\n",
       "│    └─BertPooler: 2-3                                       --\n",
       "│    │    └─Linear: 3-7                                      590,592\n",
       "│    │    └─Tanh: 3-8                                        --\n",
       "├─Dropout: 1-2                                               --\n",
       "├─Linear: 1-3                                                2,307\n",
       "=====================================================================================\n",
       "Total params: 108,312,579\n",
       "Trainable params: 108,312,579\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7ebbb0ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Yashwanth\\Jupyter\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(output_dir='training_dir',\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  save_strategy='epoch',\n",
    "                                  num_train_epochs=3,\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  per_device_eval_batch_size=64,\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29023789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8fb07af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(logits_and_labels):\n",
    "  logits, labels = logits_and_labels\n",
    "  predictions = np.argmax(logits, axis=-1)\n",
    "  acc = np.mean(predictions == labels)\n",
    "  f1 = f1_score(labels, predictions, average = 'micro')\n",
    "  return {'accuracy': acc, 'f1_score': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f84f403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 10248\n",
       "})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a2dfcf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model,\n",
    "                  training_args,\n",
    "                  train_dataset = tokenized_dataset[\"train\"],\n",
    "                  eval_dataset = tokenized_dataset[\"test\"],\n",
    "                  tokenizer=tokernizer,\n",
    "                  compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f4c69610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='637' max='1923' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 637/1923 2:25:47 < 4:55:15, 0.07 it/s, Epoch 0.99/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[1;32mC:\\Yashwanth\\Jupyter\\Lib\\site-packages\\transformers\\trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1933\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1934\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1935\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1936\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1937\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Yashwanth\\Jupyter\\Lib\\site-packages\\transformers\\trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2274\u001b[0m ):\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mC:\\Yashwanth\\Jupyter\\Lib\\site-packages\\transformers\\trainer.py:3324\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3322\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32mC:\\Yashwanth\\Jupyter\\Lib\\site-packages\\accelerate\\accelerator.py:2151\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2151\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Yashwanth\\Jupyter\\Lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32mC:\\Yashwanth\\Jupyter\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cea8db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
